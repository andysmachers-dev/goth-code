{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOhf8dpdYe04Ag8s/W6CMuy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Shivam Krishna Mishra 20230802060 Lab 05**"],"metadata":{"id":"z4Wts2LlE69W"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1dymCjqBDKtdsWgLe5_kXucKqLuYEnCN5"},"id":"pMeXFey64zwv","executionInfo":{"status":"ok","timestamp":1763585756769,"user_tz":-330,"elapsed":9681,"user":{"displayName":"Shivam Krishna Mishra","userId":"03490479620368361457"}},"outputId":"f5687534-565d-4d1a-f5eb-7a04dde0cf1d"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","plt.rcParams['figure.figsize'] = (14, 9)\n","\n","def show(title, img, cmap=None):\n","    \"\"\"Show image using matplotlib. Accepts BGR or single-channel arrays.\"\"\"\n","    if len(img.shape) == 3 and img.shape[2] == 3:\n","        # convert BGR (opencv) to RGB (for display)\n","        display = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    else:\n","        display = img\n","    plt.figure()\n","    plt.imshow(display, cmap=cmap)\n","    plt.title(title)\n","    plt.axis('off')\n","    plt.show()\n","\n","def imread_safe(path):\n","    img = cv2.imread(path)\n","    if img is None:\n","        raise FileNotFoundError(f\"Could not load '{path}'. Put the image in working directory.\")\n","    return img\n","\n","# --- load image (BGR) ---\n","img_bgr = imread_safe('/content/sfv.jpg')   # replace file name if needed\n","h, w, _ = img_bgr.shape\n","print(f\"Image shape (H,W,C): {img_bgr.shape}\")\n","\n","# Quick display\n","show(\"Original (RGB)\", img_bgr)\n","\n","# -------------------------------------------------------\n","# 1) Color space conversions\n","# -------------------------------------------------------\n","\n","img_rgb  = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n","img_hsv  = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n","img_lab  = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)\n","img_ycrcb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2YCrCb)\n","\n","show(\"RGB\", cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB))\n","show(\"HSV (visualized by converting back to RGB)\",\n","     cv2.cvtColor(img_hsv, cv2.COLOR_HSV2BGR))\n","show(\"LAB (L channel shown)\", img_lab[:, :, 0], cmap='gray')\n","\n","# -------------------------------------------------------\n","# 2) Gamma correction (gamma < 1 brighten, gamma > 1 darken)\n","# -------------------------------------------------------\n","\n","def gamma_correction(bgr, gamma):\n","    inv = 1.0 / gamma\n","    table = np.array([((i / 255.0) ** inv) * 255 for i in np.arange(256)]).astype('uint8')\n","    return cv2.LUT(bgr, table)\n","\n","gamma_08 = gamma_correction(img_bgr, 0.8)     # brighten slightly\n","gamma_12 = gamma_correction(img_bgr, 1.2)     # darken slightly\n","\n","show(\"Gamma 0.8 (brighter)\", gamma_08)\n","show(\"Gamma 1.2 (darker)\", gamma_12)\n","\n","# -------------------------------------------------------\n","# 3) Histogram equalization (global on luminance)\n","# -------------------------------------------------------\n","\n","ycrcb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2YCrCb)\n","y, cr, cb = cv2.split(ycrcb)\n","y_eq = cv2.equalizeHist(y)\n","ycrcb_eq = cv2.merge((y_eq, cr, cb))\n","img_eq_global = cv2.cvtColor(ycrcb_eq, cv2.COLOR_YCrCb2BGR)\n","\n","show(\"Histogram Equalized (global on Y channel)\", img_eq_global)\n","\n","# -------------------------------------------------------\n","# 4) Color segmentation (red detection demo)\n","# -------------------------------------------------------\n","\n","lower_red1 = np.array([0, 70, 50])\n","upper_red1 = np.array([10, 255, 255])\n","lower_red2 = np.array([170, 70, 50])\n","upper_red2 = np.array([180, 255, 255])\n","\n","mask1 = cv2.inRange(img_hsv, lower_red1, upper_red1)\n","mask2 = cv2.inRange(img_hsv, lower_red2, upper_red2)\n","mask = mask1 | mask2\n","\n","segmented = cv2.bitwise_and(img_bgr, img_bgr, mask=mask)\n","show(\"Segmented red regions\", segmented)\n","\n","# -------------------------------------------------------\n","# 8) Color smoothing and sharpening\n","# -------------------------------------------------------\n","\n","# Bilateral Filter (edge-preserving smoothing)\n","bilat = cv2.bilateralFilter(img_bgr, d=9, sigmaColor=75, sigmaSpace=75)\n","show(\"Bilateral Filter (color-preserving smoothing)\", bilat)\n","\n","# Sharpening using Unsharp Mask\n","def unsharp_mask_color(bgr, kernel_size=(5,5), sigma=1.0, amount=1.0, threshold=0):\n","    blurred = cv2.GaussianBlur(bgr, kernel_size, sigma)\n","    sharpened = cv2.addWeighted(bgr, 1 + amount, blurred, -amount, 0)\n","    return sharpened\n","\n","sharpened = unsharp_mask_color(img_bgr, kernel_size=(5,5), sigma=1.0, amount=0.8)\n","show(\"Sharpened (Unsharp Mask)\", sharpened)\n","\n","# -------------------------------------------------------\n","# 9) Blend two color-processed versions\n","# -------------------------------------------------------\n","\n","# CLAHE (prep)\n","lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)\n","l, a, b = cv2.split(lab)\n","clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n","l_clahe = clahe.apply(l)\n","img_clahe = cv2.cvtColor(cv2.merge((l_clahe, a, b)), cv2.COLOR_LAB2BGR)\n","\n","blend = cv2.addWeighted(img_bgr, 0.6, img_clahe, 0.4, 0)\n","show(\"Blend: original (0.6) + CLAHE (0.4)\", blend)\n","\n","# -------------------------------------------------------\n","# 10) Save some outputs (optional)\n","# -------------------------------------------------------\n","cv2.imwrite('img_gamma08.png', gamma_08[:, :, ::-1])  # convert BGR->RGB before saving\n","cv2.imwrite('img_clahe.png', img_clahe)\n","cv2.imwrite('img_quantized.png', img_clahe)  # screenshot showed quantized saved same variable\n","\n","print(\"Saved outputs: img_gamma08.png, img_clahe.png, img_quantized.png (in working directory).\")\n","print(\"Done. Techniques applied: color conversions, gamma, equalization, CLAHE, white balance, segmentation, quantization, smoothing & sharpening.\")\n"]}]}